##1.5 本书概述

&emsp;&emsp;鉴于目前缺少系统的讲解如何在FPGA上实现深度学习加速器的教材，尤其是缺少能够介绍完整的设计流程（不仅仅是FPGA设计，还有包括模型的训练、量化，编译工具的开发等），缺少各种技术实现细节的教程。为了给初学者提供入门级的培训，本教程从原理、工具链和具体实现的角度，详细的介绍神经网络加速器的设计原理、设计流程、工具链和各种实现细节。着重解决涉及到的各个技术点、需要做的各种权衡与妥协。

&emsp;&emsp;本书试图拆解整个深度学习加速器的设计流程，使得开发人员尽快了解神经网络加速器开发所需的全部技术栈。当然本文档选择的技术路线不一定是最优的，所使用的技术也不一定是最先进的。然而，按照本文档的步骤进行操作，可以较为容易的实现一个神经网络加速器。如果人员配置较为充裕，设计流程中的每一步骤都有充分的优化空间，可以在基础版加速器的基础上进一步的优化。

&emsp;&emsp;受限于书篇幅，本书只讲解神经网络中最为基本的算子，这些算子能够搭建大部分神经网络。一旦网络结构必须使用一些特殊的算子，一种解决方案是将中间结果传回CPU，使用CPU处理，计算完成后，重新传给FPGA处理；另一种解决办法是开发自定义的算子。本文档制定了一组算子开发规范，按照这组开发规范，可以快速的实现自定义算子的开发以及工具链的集成。

&emsp;&emsp;与此同时，本书开发了一系列的工具集（链），这些工具可以辅助和加快开发的进度。当然这些程序应该进一步完善，并进一步采用自动的方式，协助生成指令等。然而，受人手的限制，没有完成相应的开发，尤其应该与诸如TVM等编译器进行对接，这将是作者接下来的工作。

&emsp;&emsp;本书也同时讲解使用高级语言（SpinalHDL）开发神经网络加速器的方法。高级语言能极大的节约开发时间，具有更好的可移植性，但是SpinalHDL是构建在Scala的基础上的领域专用语言，学习门槛非常高，尤其是需要在熟悉Verilog和Scala的基础上才能进行开发。高级语言选择SpinalHDL的原因是其更适合描述神经网络加速器。与SpinalHDL类似，开发人员也可以用Chisel进行代码实现。 

&emsp;&emsp;至于对ZYNQ平台的支持，也是本书的一部分内容，但不是重点内容。鉴于Xilinx的DPU和Vitis AI平台在逐步的成熟，在ZYNQ平台首选的组合应该是DPU+Vitis AI，而不是自己开发加速器。当然，DPU并没有针对普通用户开发自定义算子的功能，遇到不支持算子时，处理起来将非常困难。
